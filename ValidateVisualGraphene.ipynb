{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import multi_gpu_model\n",
    "import tensorflow as tf\n",
    "from temnn.knet import net\n",
    "#from temdata.dataset import DataEntry,DataSet\n",
    "from temnn.net.dataset import DataEntry,DataSet\n",
    "from pyqstem.imaging import CTF\n",
    "import matplotlib.pyplot as plt\n",
    "# Peak detection\n",
    "from stm.preprocess import normalize\n",
    "from stm.feature.peaks import find_local_peaks, refine_peaks\n",
    "from skimage.morphology import disk\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "import sys\n",
    "import os\n",
    "from collections import deque\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folders\n",
    "data_dir = \"data/graphene-random/\"\n",
    "#validation_dir = \"data/cluster-110-single-class-test/\"\n",
    "validation_dir = data_dir  # A big no-no\n",
    "graph_dir = 'graphs-graphene-hidose'\n",
    "graph_path = os.path.join(graph_dir, 'clusters-{:d}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microscope parameters\n",
    "#sampling=0.11953 #244.8/2048\n",
    "sampling=0.12\n",
    "Cs=-10e4\n",
    "defocus=90\n",
    "focal_spread=30\n",
    "blur=1.5\n",
    "#dose=5*10**2\n",
    "dose = 2e4\n",
    "mtf_param=[1,0,4.89683027e-01,2.34644273e+00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 1\n",
    "batch_size = 8 * num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(data_dir):\n",
    "    \"Load data folder.\"\n",
    "    #models=sorted(glob(data_dir+\"model/model_*.cfg\"))\n",
    "    waves=sorted(glob(data_dir+\"wave/wave_*.npz\"))\n",
    "    #labels=sorted(glob(data_dir+\"label/label_*.npy\"))\n",
    "    points=sorted(glob(data_dir+\"points/points_*.npz\"))\n",
    "    #entries=[DataEntry(model,wave,label) for model,wave,label in zip(models,waves,labels)]\n",
    "    entries = [DataEntry(wave=w, points=p) for w,p in zip(waves,points)]\n",
    "\n",
    "    return DataSet(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CNN(graph_path, size, num_gpus=1):\n",
    "    \"Load the Keras neural net, and return a Model.\"\n",
    "    kernel_num=32\n",
    "    image_features=1\n",
    "    num_classes=1\n",
    "\n",
    "    if num_gpus == 1:\n",
    "        x = keras.Input(shape=size+(image_features,))\n",
    "        model = net.graph(x, output_features=num_classes)\n",
    "        model.load_weights(graph_path)\n",
    "    else:\n",
    "        with tf.device('/cpu:0'):\n",
    "            x = keras.Input(shape=size+(image_features,))\n",
    "            model = net.graph(x, output_features=num_classes)\n",
    "            model.load_weights(graph_path)\n",
    "        model = multi_gpu_model(model, gpus=num_gpus)\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "    \n",
    "    return (x, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeimage(entry, size):\n",
    "    entry.load()    \n",
    "    ctf=CTF(defocus=defocus,Cs=Cs,focal_spread=focal_spread)\n",
    "    entry.create_image(ctf,sampling,blur,dose,mtf_param)\n",
    "    entry.create_label(sampling, width = int(.4/sampling), num_classes=False)\n",
    "\n",
    "    entry.local_normalize(12./sampling, 12./sampling)\n",
    "    shape = entry._image.shape[1:3]\n",
    "    assert not ((size[0] > shape[0]) != (size[1] > shape[1]))\n",
    "    if shape[0] > size[1]:\n",
    "        assert shape[1] >= size[1]\n",
    "        entry.random_crop(size, sampling)\n",
    "    elif shape[0] < size[1]:\n",
    "        assert shape[1] <= size[1]\n",
    "        entry.pad(size)\n",
    "    else:\n",
    "        assert shape[1] == size[1]\n",
    "\n",
    "    image,label=entry.as_tensors()\n",
    "    entry.reset()\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Use multiprocessing to generate many sample datasets\n",
    "class MakeImages:\n",
    "    def __init__(self, data, imagesize):\n",
    "        self.data = data\n",
    "        self.precomputed = []\n",
    "        self.batchsize = 10\n",
    "        self.imagesize = np.array(imagesize)\n",
    "\n",
    "    def precompute(self):\n",
    "        #print(\"Precomputing {} images.\".format(self.batchsize), flush=True)\n",
    "        entries = self.data.next_batch(self.batchsize, shuffle=False)\n",
    "        imagesizes = self.imagesize[np.newaxis,:] * np.ones(self.batchsize, int)[:,np.newaxis]\n",
    "        with Pool() as pool:\n",
    "            self.precomputed = deque(pool.starmap(makeimage,  zip(entries, imagesizes)))\n",
    "\n",
    "    def next_example(self):\n",
    "        if not self.precomputed:\n",
    "            self.precompute()\n",
    "        return self.precomputed.popleft()\n",
    "\n",
    "    def get_all_examples(self):\n",
    "        \"Get an example from each data point.\"\n",
    "        n = self.data.num_examples\n",
    "        entries = self.data.next_batch(n, shuffle=False)\n",
    "        imagesizes = self.imagesize[np.newaxis,:] * np.ones(n, int)[:,np.newaxis]\n",
    "        images = []\n",
    "        labels = []\n",
    "        with Pool() as pool:\n",
    "            for img, lbl in pool.starmap(makeimage, zip(entries, imagesizes)):\n",
    "                images.append(img)\n",
    "                labels.append(lbl)\n",
    "        return np.concatenate(images), np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(predicted, target, distance=0.5/sampling):\n",
    "    \"\"\"Precision and recall for peak positions\"\"\"\n",
    "    # Precision: Number of correctly predicted peaks \n",
    "    # divided by number of target peaks\n",
    "    if len(predicted) == 0:\n",
    "        return (0.0, 1.0)\n",
    "    if len(target) == 0:\n",
    "        return (1.0, 0.0)\n",
    "    tree = KDTree(target)\n",
    "    print(\"Distance(T)\", distance)\n",
    "    x = tree.query(predicted, distance_upper_bound=distance)[0]\n",
    "    precision = (x <= distance).sum() / len(predicted)\n",
    "    # Recall: Number of target peaks that were found\n",
    "    # divided by total number of target peaks\n",
    "    tree = KDTree(predicted)\n",
    "    x = tree.query(target, distance_upper_bound=distance)[0]\n",
    "    recall = (x <= distance).sum() / len(target)\n",
    "    return (precision, recall)\n",
    "\n",
    "def evaluate_result(inference, label):\n",
    "    \"Evaluate the prediction for an image.\"\n",
    "    # Find the peaks\n",
    "    distance = 1.0 / sampling\n",
    "    print(\"Distance\", distance)\n",
    "    infer_peaks = find_local_peaks(inference[:,:,0], min_distance=distance, \n",
    "                                   threshold=0.5, exclude_border=10,\n",
    "                                   exclude_adjacent=True)\n",
    "    label_peaks = find_local_peaks(label[:,:,0], min_distance=distance, \n",
    "                                   threshold=0.5, exclude_border=10,\n",
    "                                   exclude_adjacent=True)\n",
    "\n",
    "    # Refine the peaks\n",
    "    region = disk(2)\n",
    "    infer_refined = refine_peaks(normalize(inference[:,:,0]), infer_peaks, \n",
    "                                region, model='polynomial')\n",
    "    label_refined = refine_peaks(normalize(label[:,:,0]), label_peaks, \n",
    "                                region, model='polynomial')\n",
    "    precision, recall = precision_recall(infer_refined, label_refined)\n",
    "    return (precision, recall, infer_refined, label_refined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The action starts here !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (360,360)\n",
    "data_train = load(data_dir)\n",
    "imagestream_train = MakeImages(data_train, image_size)\n",
    "n_train = data_train.num_examples\n",
    "print(\"Number of training images:\", n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the latest CNN\n",
    "print(\"Looking for CNNs in files matching\", graph_path)\n",
    "for i in range(100):\n",
    "    if os.path.exists(graph_path.format(i)):\n",
    "        gr = graph_path.format(i)\n",
    "\n",
    "print(\"Using CNN parameters in\", gr)\n",
    "x, model = load_CNN(gr, image_size, num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n_train\n",
    "imagestream = imagestream_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = imagestream.next_example()\n",
    "print(image.shape, label.shape)\n",
    "predictions = model.predict(image)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prec, rec, pred_pos, lbl_pos = evaluate_result(predictions[0],label[0])\n",
    "print(\"Peaks in labels\", len(lbl_pos))\n",
    "print(\"Peaks in prediction\", len(pred_pos))\n",
    "print(\"Precision, recall\", prec, rec)\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4,1,figsize=(6,30))\n",
    "im1 = ax1.imshow(image[0,:,:,0].T,cmap='gray')\n",
    "im2 = ax2.imshow(label[0,:,:,0].T,cmap='gray')\n",
    "im3 = ax3.imshow(predictions[0,:,:,0].T,cmap='gray')\n",
    "ax4.imshow(np.zeros_like(image)[0,:,:,0].T, cmap='gray')\n",
    "ax4.scatter(lbl_pos[:,0], lbl_pos[:,1], c='r', marker='+', linewidth=.6)\n",
    "ax4.scatter(pred_pos[:,0], pred_pos[:,1], c='g', marker='+', linewidth=.6)\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "ax3.axis('off')\n",
    "ax4.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
